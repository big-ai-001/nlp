{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.layers import Loss\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer, load_vocab\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, open\n",
    "from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n",
    "from keras.models import Model\n",
    "from rouge import Rouge  # pip install rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom transformers import (\\n   BertTokenizerFast,\\n   AutoModelForMaskedLM,\\n   AutoModelForCausalLM,\\n   AutoModelForTokenClassification,\\n)\\n\\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\\nmodel = AutoModelForMaskedLM.from_pretrained('ckiplab/albert-tiny-chinese') # or other models above\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 256\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "config_path = \"./model/bert_base/chinese_L-12_H-768_A-12/bert_config.json\"\n",
    "checkpoint_path = './model/bert_base/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = './model/bert_base/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "'''\n",
    "from transformers import (\n",
    "   BertTokenizerFast,\n",
    "   AutoModelForMaskedLM,\n",
    "   AutoModelForCausalLM,\n",
    "   AutoModelForTokenClassification,\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = AutoModelForMaskedLM.from_pretrained('ckiplab/albert-tiny-chinese') # or other models above\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            title, content = l.strip().split('\\t')\n",
    "            D.append((title, content))\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvalid_data = load_data('/root/csl/val.tsv')\\ntest_data = load_data('/root/csl/test.tsv')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = load_data('./dataset/train.tsv')\n",
    "'''\n",
    "valid_data = load_data('/root/csl/val.tsv')\n",
    "test_data = load_data('/root/csl/test.tsv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data=train_data[9000:9500]\n",
    "test_data=train_data[9500:10000]\n",
    "train_data=train_data[0:9000]\n",
    "np.shape(valid_data)\n",
    "#len(test_data)\n",
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict, keep_tokens = load_vocab(\n",
    "    dict_path=dict_path,\n",
    "    simplified=True,\n",
    "    startswith=['[PAD]', '[UNK]', '[CLS]', '[SEP]'],\n",
    ")\n",
    "tokenizer = Tokenizer(token_dict, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids = [], []\n",
    "        for is_end, (title, content) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                content, title, maxlen=maxlen\n",
    "            )\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                yield [batch_token_ids, batch_segment_ids], None\n",
    "                batch_token_ids, batch_segment_ids = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Loss):\n",
    "    def compute_loss(self, inputs, mask=None):\n",
    "        y_true, y_mask, y_pred = inputs\n",
    "        y_true = y_true[:, 1:] \n",
    "        y_mask = y_mask[:, 1:] \n",
    "        y_pred = y_pred[:, :-1] \n",
    "        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     multiple             10432512    Input-Token[0][0]                \n",
      "                                                                 MLM-Norm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Attention-UniLM-Mask (Lambda)   (None, 1, None, None 0           Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, None, 768)    590592      Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, None, 768)    1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Bias (BiasAdd)              (None, None, 13584)  13584       Embedding-Token[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Activation (Activation)     (None, None, 13584)  0           MLM-Bias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_entropy (CrossEntropy)    (None, None, 13584)  0           Input-Token[0][0]                \n",
      "                                                                 Input-Segment[0][0]              \n",
      "                                                                 MLM-Activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 96,488,976\n",
      "Trainable params: 96,488,976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    application='unilm',\n",
    "    keep_tokens=keep_tokens,\n",
    ")\n",
    "\n",
    "output = CrossEntropy(2)(model.inputs + model.outputs)\n",
    "\n",
    "model = Model(model.inputs, output)\n",
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoTitle(AutoRegressiveDecoder):\n",
    "    @AutoRegressiveDecoder.wraps(default_rtype='probas')\n",
    "    def predict(self, inputs, output_ids, states):\n",
    "        token_ids, segment_ids = inputs\n",
    "        token_ids = np.concatenate([token_ids, output_ids], 1)\n",
    "        segment_ids = np.concatenate([segment_ids, np.ones_like(output_ids)], 1)\n",
    "        return self.last_token(model).predict([token_ids, segment_ids])\n",
    "\n",
    "    def generate(self, text, topk=1):\n",
    "        max_c_len = maxlen - self.maxlen\n",
    "        token_ids, segment_ids = tokenizer.encode(text, maxlen=max_c_len)\n",
    "        output_ids = self.beam_search([token_ids, segment_ids],\n",
    "                                      topk=topk) \n",
    "        return tokenizer.decode(output_ids)\n",
    "\n",
    "\n",
    "autotitle = AutoTitle(start_id=None, end_id=tokenizer._token_end_id, maxlen=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selab-001\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - ETA: 0s - loss: 2.7609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:33<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6158028539136735, 'rouge-2': 0.4951348180758301, 'rouge-l': 0.5907854962074148, 'bleu': 0.3741351440615922, 'best_bleu': 0.3741351440615922}\n",
      "563/563 [==============================] - 2070s 4s/step - loss: 2.7609\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.5075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:17<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6303881819544842, 'rouge-2': 0.5159175007689925, 'rouge-l': 0.6018499868342577, 'bleu': 0.4054622997095951, 'best_bleu': 0.4054622997095951}\n",
      "563/563 [==============================] - 1984s 4s/step - loss: 1.5075\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.3395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:58<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6398425442957897, 'rouge-2': 0.5215151045535682, 'rouge-l': 0.6101409477645894, 'bleu': 0.41144678693336645, 'best_bleu': 0.41144678693336645}\n",
      "563/563 [==============================] - 2028s 4s/step - loss: 1.3395\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.2394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [21:57<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6543956022717533, 'rouge-2': 0.5379111348429688, 'rouge-l': 0.6257551342575403, 'bleu': 0.42685993125671584, 'best_bleu': 0.42685993125671584}\n",
      "563/563 [==============================] - 1968s 3s/step - loss: 1.2394\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.1727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:59<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6480196514713105, 'rouge-2': 0.5304925572539216, 'rouge-l': 0.618494106390483, 'bleu': 0.42074405775929713, 'best_bleu': 0.42685993125671584}\n",
      "563/563 [==============================] - 2022s 4s/step - loss: 1.1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.1172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:16<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6608329383356449, 'rouge-2': 0.5438695462165654, 'rouge-l': 0.630275185410816, 'bleu': 0.4358682638637675, 'best_bleu': 0.4358682638637675}\n",
      "563/563 [==============================] - 1985s 4s/step - loss: 1.1172\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.0711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [21:38<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.659563577450352, 'rouge-2': 0.5429167810856941, 'rouge-l': 0.6300751416493777, 'bleu': 0.43956474512983784, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 1949s 3s/step - loss: 1.0711\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 1.0215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:40<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6543015097287772, 'rouge-2': 0.5371970492823226, 'rouge-l': 0.6229113236328293, 'bleu': 0.4337961845142361, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 2003s 4s/step - loss: 1.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.9829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:34<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.658907389833466, 'rouge-2': 0.5389963325073988, 'rouge-l': 0.6260189168115922, 'bleu': 0.4346950010241607, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 1997s 4s/step - loss: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.9502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:04<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6577414617170784, 'rouge-2': 0.5364974917938595, 'rouge-l': 0.6249216077659924, 'bleu': 0.43225270446180164, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 2036s 4s/step - loss: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.9162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [21:29<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6532514769268096, 'rouge-2': 0.5324391080840587, 'rouge-l': 0.6217920989635052, 'bleu': 0.4253526344863265, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 1942s 3s/step - loss: 0.9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.8862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:57<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.662291536150974, 'rouge-2': 0.5410714141210865, 'rouge-l': 0.6282255752851701, 'bleu': 0.43527866256301384, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 2091s 4s/step - loss: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.8606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:41<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6560350380753381, 'rouge-2': 0.5351827340365641, 'rouge-l': 0.622198318078268, 'bleu': 0.4293557398438032, 'best_bleu': 0.43956474512983784}\n",
      "563/563 [==============================] - 2014s 4s/step - loss: 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.8323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:25<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.663918848924954, 'rouge-2': 0.5451749799858874, 'rouge-l': 0.6313485775665693, 'bleu': 0.44398242698145746, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2125s 4s/step - loss: 0.8323\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.8088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:32<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6580831845254097, 'rouge-2': 0.5370870195602019, 'rouge-l': 0.6246869335287693, 'bleu': 0.43476821360323853, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2059s 4s/step - loss: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.7822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:07<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6665853120042355, 'rouge-2': 0.546766486183051, 'rouge-l': 0.6302490393035053, 'bleu': 0.4418812179562024, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2029s 4s/step - loss: 0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.7597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:02<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6608295575301463, 'rouge-2': 0.53913765258246, 'rouge-l': 0.6236618592851628, 'bleu': 0.4364103362856684, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2086s 4s/step - loss: 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.7378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:08<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6590463899367772, 'rouge-2': 0.540132856037617, 'rouge-l': 0.6244007096911808, 'bleu': 0.4368373138606962, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2093s 4s/step - loss: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.7148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:42<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6494262525823564, 'rouge-2': 0.5280974838474484, 'rouge-l': 0.6154502923262284, 'bleu': 0.4241011663078994, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2070s 4s/step - loss: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.6982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:07<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data: {'rouge-1': 0.6568439072329715, 'rouge-2': 0.5342690418332792, 'rouge-l': 0.6195137798868043, 'bleu': 0.430800833757064, 'best_bleu': 0.44398242698145746}\n",
      "563/563 [==============================] - 2099s 4s/step - loss: 0.6982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.rouge = Rouge()\n",
    "        self.smooth = SmoothingFunction().method1\n",
    "        self.best_bleu = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = self.evaluate(valid_data) \n",
    "        if metrics['bleu'] > self.best_bleu:\n",
    "            self.best_bleu = metrics['bleu']\n",
    "            model.save_weights('./best_model/best_model.weights') \n",
    "        metrics['best_bleu'] = self.best_bleu\n",
    "        print('valid_data:', metrics)\n",
    "\n",
    "    def evaluate(self, data, topk=1):\n",
    "        total = 0\n",
    "        rouge_1, rouge_2, rouge_l, bleu = 0, 0, 0, 0\n",
    "        for title, content in tqdm(data):\n",
    "            total += 1\n",
    "            title = ' '.join(title).lower()\n",
    "            pred_title = ' '.join(autotitle.generate(content, topk)).lower()\n",
    "            if pred_title.strip():\n",
    "                scores = self.rouge.get_scores(hyps=pred_title, refs=title)\n",
    "                rouge_1 += scores[0]['rouge-1']['f']\n",
    "                rouge_2 += scores[0]['rouge-2']['f']\n",
    "                rouge_l += scores[0]['rouge-l']['f']\n",
    "                bleu += sentence_bleu(\n",
    "                    references=[title.split(' ')],\n",
    "                    hypothesis=pred_title.split(' '),\n",
    "                    smoothing_function=self.smooth\n",
    "                )\n",
    "        rouge_1 /= total\n",
    "        rouge_2 /= total\n",
    "        rouge_l /= total\n",
    "        bleu /= total\n",
    "        return {\n",
    "            'rouge-1': rouge_1,\n",
    "            'rouge-2': rouge_2,\n",
    "            'rouge-l': rouge_l,\n",
    "            'bleu': bleu,\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    train_generator = data_generator(train_data, batch_size)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator.forfit(),\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        callbacks=[evaluator]\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    model.load_weights('./best_model.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3463579379728475991, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10175972952992078534\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6934559456\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16742833666877936717\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:9e:00.0, compute capability: 7.5\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 17294182559736239460\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"RECOMPUTE\"]='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文:為解決車載自組織網路負載較重時控制通道擁塞和通道利用率低的問題,提出一種分時多工機制的非同步車載自組織網多通道MAC(Media Access Control)協議——ATMP(Asynchronous TDMA-based multi-channel MAC Protocol).ATMP協議採用分時多工的非同步接入機制實現節點分時段接入控制通道,減少併發接入控制通道的節點數目,降低碰撞概率;進一步,為了解決多通道協調資訊丟失問題,ATMP協議使用節點協作機制來獲取節點遺漏的通道協調資訊,有效降低因協調資訊缺失造成的資料通道服務資訊碰撞概率.模擬結果表明,ATMP協議在碰撞概率、安全訊息時延及控制通道吞吐量指標上優於IEEE1609.4標準、AMCP協議和AMCMAC協議.\n",
      "人工摘要:車載自組織網路中基於分時多工的非同步多通道MAC協議\n",
      "機器摘要:分時多工機制的非同步車載自組織網多通道mac協議協議\n",
      "原文:分析現有一些Vague集相似度量方法,並指出其不足。考慮在實際應用中,未知度對相似度量的影響,從動態的角度出發,挖掘未知度中包含的贊成與反對資訊,提出了一種基於未知度的Vague集相似度量新方法,並將該相似度量方法應用於模糊資料檢測中,通過實際應用說明該方法更加有效。\n",
      "人工摘要:Vague集相似度量及其在模糊資料檢測中的應用\n",
      "機器摘要:基於未知度的vague集相似度量方法\n",
      "原文:目的:與CAG對照分析來評價64層螺旋CT冠狀動脈成像在房顫患者中診斷有血流動力學意義的冠狀動脈狹窄的準確性。方法:58例房顫患者行64層螺旋CT冠狀動脈成像,掃描前均未服用倍它樂克。血管影象質量分為好、中等和差。以CAG作為參考標準,分別基於血管節段和患者水平來分析MDCTCA診斷有血流動力學意義的冠狀動脈狹窄的敏感性、特異性、陽性預測價值和陰性預測價值。診斷價值的評價首先僅限於影象質量達到診斷要求的血管節段和患者,進一步的分析中將影象質量不能診斷的血管節段和患者均作為陽性來處理。結果:58例患者有645段(96.55%)影象質量為中等以上,診斷有血流動力學意義的敏感性、特異性、陽性預測價值和陰性預測價值分別是86.21%(25/29)、99.35%(612/616)、86.21%(25/29)和99.35%(612/616)。將23段影象質量沒有達到診斷要求的血管均作為陽性後,CTCA診斷有血流動力學意義的血管狹窄的總體陽性預測價值為48.08%(25/52),特異性為95.77%(612/639)。基於患者總體影象質量的分析,58例患者中有47例(81.03%)影象質量為中等以上,CTCA診斷有血流動力學意義的敏感性、特異性、陽性預測價值和陰性預測價值分別是87.50%(7/8)、97.44%(38/39)、87.50%(7/8)和97.44%(38/39)。將11例影象質量沒有達到診斷要求的血管均作為陽性後,CTCA診斷有血流動力學意義的血管狹窄的敏感性、特異性、陽性預測價值和陰性預測價值分別是90.00%(9/10)、79.17%(38/48)、47.37%(9/19)和97.44%(38/39)。結論:64CTCA在房顫患者中診斷有血流動力學意義的冠狀動脈狹窄具有較好的陰性預測價值,但需要進一步提高影象質量來提高診斷血管狹窄的準確性。\n",
      "人工摘要:64層CTA診斷房顫患者冠狀動脈狹窄準確性的臨床研究\n",
      "機器摘要:64層螺旋ct冠狀動脈成像在房顫患者中的診斷價值分析\n",
      "原文:執行時驗證一般採用時態邏輯來描述要驗證的需求規約,並根據需求規約構造監控器.這對於那些沒有形式化經驗的軟體工程師而言,是一件非常困難的事情,同時,這類方法通常缺少時間機制支撐,因此難以滿足實時系統執行時驗證中的要求.序列圖得到了廣泛使用,研究基於序列圖來自動生成監控器就顯得十分有意義.提出基於UML2.0時間屬性序列圖的監控器的自動生成方法,其具體思想是使用時間屬性序列圖來描述要驗證的需求規約,然後將整個序列圖轉換為時間自動機網路,構造出監控器.實驗表明,該方法方便缺少形式化經驗的軟體工程師使用,所產生的監控器執行開銷較小,能滿足驗證對實時性的要求,且有效緩解了監控器生成過程中的組合爆炸.\n",
      "人工摘要:基於時間屬性序列圖的監控器構造方法\n",
      "機器摘要:基於uml2.0時間屬性序列圖的實時系統執行時驗證監控器的研究\n",
      "原文:針對目前廣泛使用的H.264標準,設計了一種基於SDL和ffmpeg的流媒體播放系統.將經過RTP封裝的流媒體資訊解除封裝處理後,利用ffmpeg良好的解碼能力對資料進行解碼,之後再利用SDL優異的視訊效能進行實時顯示,並同時將流媒體資料儲存在本地以供隨時呼叫.實驗證明,該播放系統解碼播放的實時性出色,畫質良好,此外憑藉ffmpeg和SDL的跨平臺特性,系統具有良好的移植性和拓展性,適用於嵌入式裝置和手機平臺.\n",
      "人工摘要:基於SDL的H.264流媒體播放系統\n",
      "機器摘要:基於sdl和ffmpeg的流媒體播放系統\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('原文:'+test_data[i][1])\n",
    "    print('人工摘要:'+test_data[i][0])\n",
    "    print('機器摘要:'+autotitle.generate(test_data[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文:在就一心有一個報導提出，目前針對早期新冠肺炎的唯一治療方法，那很多一聲卻不知道，所以想請問您不是這篇報導所說的，唯一治療方法是哪一種治療方法呢？今天的報導，這個也搞的有點神色醫師喔？現在看那個標題寫的好像有一個靈丹妙藥，大家都給忽視掉，那其實並不是這樣的。那篇報導裡面提到一九九四單克隆抗體療法，那實際上，美帝陸續有報導，那麼他這個改版都只是要強調就是很多醫生，其實並沒有很充分的陰影，有這樣一個工具就是當克隆抗體的這個治療的方案來，真的一些病人特別是對於早期患有無精症，阿或者是中度症狀，的病人，還有一些情況可以用來去向來是怕被來這就是預防性的治療，所以這份報告，我覺得就是提醒而已。省，其實你是有一個額外的工具是可以用的，並不是說，病人來了。\n",
      "摘要:面向早期新冠肺炎的克隆抗體治療方法研究\n"
     ]
    }
   ],
   "source": [
    "s=\"在就一心有一個報導提出，目前針對早期新冠肺炎的唯一治療方法，那很多一聲卻不知道，所以想請問您不是這篇報導所說的，唯一治療方法是哪一種治療方法呢？今天的報導，這個也搞的有點神色醫師喔？現在看那個標題寫的好像有一個靈丹妙藥，大家都給忽視掉，那其實並不是這樣的。那篇報導裡面提到一九九四單克隆抗體療法，那實際上，美帝陸續有報導，那麼他這個改版都只是要強調就是很多醫生，其實並沒有很充分的陰影，有這樣一個工具就是當克隆抗體的這個治療的方案來，真的一些病人特別是對於早期患有無精症，阿或者是中度症狀，的病人，還有一些情況可以用來去向來是怕被來這就是預防性的治療，所以這份報告，我覺得就是提醒而已。省，其實你是有一個額外的工具是可以用的，並不是說，病人來了。\"\n",
    "print(\"原文:\"+s)\n",
    "print(\"摘要:\"+autotitle.generate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2e925ec4b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./best_model/best_model.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cdc6226152ad3ad8a56f8e4518cb7f834e235f46caa02a52bcd8ef4d8777820"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
